{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ce00400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import SETR\n",
    "import torch.nn.functional as F \n",
    "import torchvision \n",
    "import numpy as np \n",
    "import PIL\n",
    "from PIL import Image, ImageFilter \n",
    "import os \n",
    "import random\n",
    "import glob\n",
    "import pdb\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms.functional as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c065d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(images_list) : \n",
    "    pixels = [] \n",
    "    for i, filepath in enumerate(images_list) : \n",
    "        img = Image.open(filepath)\n",
    "        try : \n",
    "            img = tf.to_tensor(img) \n",
    "            pixels.append(img.view(-1))\n",
    "        except TypeError : \n",
    "            print(f'{filepath} is truncated')\n",
    "        if i % 500 == 0 : \n",
    "            print(f'{i}/{len(images_list)}')\n",
    "        if i == 2000 :\n",
    "            break # Out of memory..\n",
    "    pixels = torch.cat(pixels, dim=0)\n",
    "    return torch.std_mean(pixels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5cfd4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_transform(*images) : \n",
    "    w,h = images[0].size # assuming w=512, h<=1024\n",
    "    assert w == 512 \n",
    "    if h < 1024 : \n",
    "        # pad to 1024\n",
    "        diff = 1024-h \n",
    "        images =  [tf.pad(image, (0,0,diff//2, diff-diff//2)) for image in images]\n",
    "    w,h = images[0].size\n",
    "    assert h == 1024\n",
    "    \n",
    "    # random horizontal flip\n",
    "    if random.random() < 0.5 : \n",
    "        images = [tf.hflip(image) for image in images]\n",
    "    \n",
    "    # random pad\n",
    "    #if random.random() < 0.5 : \n",
    "    #    images = [tf.pad(image, 64) for image in images]\n",
    "    \n",
    "    # random rotation\n",
    "    angle = 0 \n",
    "    if random.random() < 0.5 : \n",
    "        angle = random.randint(-15, 15)\n",
    "        #images = [tf.rotate(image, angle, resample=PIL.Image.BILINEAR) for image in images]\n",
    "    \n",
    "    # random scale \n",
    "    scale = 1 \n",
    "    if random.random() < 0.5 : \n",
    "        scale = random.uniform(7/8, 9/8)\n",
    "    \n",
    "    images = [tf.affine(image, angle=angle, scale=scale, translate = (0,0), shear=0,\n",
    "                        resample = PIL.Image.BILINEAR) for image in images]\n",
    "    \n",
    "    images = [tf.pad(image, 64) for image in images]\n",
    "    \n",
    "    W,H = images[0].size \n",
    "    assert H >= h \n",
    "    assert W >= w \n",
    "    \n",
    "    h_diff = H-h\n",
    "    w_diff = W-w \n",
    "    \n",
    "    if random.random() < 0.5 : \n",
    "        # Center crop with 50% chance \n",
    "        h_start, w_start = h_diff//2, w_diff//2\n",
    "    else : \n",
    "        h_start, w_start = random.randint(0, h_diff), random.randint(0, w_diff)\n",
    "    \n",
    "    images = [tf.crop(image, h_start, w_start, h, w) for image in images]\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72f61827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_to_channels(target) : \n",
    "    target = (tf.to_tensor(target)*255).int()\n",
    "    c,h,w = target.shape \n",
    "    assert c == 1 \n",
    "    target = target.squeeze(0).numpy() # (h,w)\n",
    "    \n",
    "    output = np.zeros((h,w,3), dtype=np.uint8)\n",
    "    output[:,:,0] = (target==1).astype(np.uint8)*255\n",
    "    output[:,:,1] = (target==2).astype(np.uint8)*255\n",
    "    output[:,:,2] = (target==3).astype(np.uint8)*255\n",
    "    \n",
    "    return Image.fromarray(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ea0fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class oct_dataset(object) : \n",
    "    def __init__(self, data_path='/../../linux_share/oct_images/images', label_path='/../../linux_share/oct_images/labels', \n",
    "                 sync_transform = None, transform=None) : \n",
    "        self.data = []\n",
    "        self.transform=transform\n",
    "        self.sync_transform = sync_transform\n",
    "        self.totensor = torchvision.transforms.ToTensor()\n",
    "        \n",
    "        filenames = os.listdir(data_path)\n",
    "        self.data = [(os.path.join(data_path,filename),os.path.join(label_path,filename)) for filename in filenames]\n",
    "        \n",
    "            \n",
    "    def __len__(self) : \n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index) : \n",
    "        image_path, label_path = self.data[index]\n",
    "        image_name = os.path.basename(image_path)\n",
    "        \n",
    "        \n",
    "        image = Image.open(image_path)\n",
    "        label = Image.open(label_path)\n",
    "        label = integer_to_channels(label)\n",
    "        \n",
    "        if self.sync_transform is not None : \n",
    "            image, label = self.sync_transform(image, label)\n",
    "        if self.transform is not None : \n",
    "            image = self.transform(image)\n",
    "            \n",
    "        image = image.filter(ImageFilter.MedianFilter(size = 5)) \n",
    "        \n",
    "        image = self.totensor(image)\n",
    "        label = self.totensor(label)\n",
    "        \n",
    "        if True : \n",
    "            image = tf.normalize(image, 0.1410, 0.0941, inplace=True)\n",
    "            \n",
    "        label = label*255 \n",
    "        \n",
    "        return image, label,image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf27a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = oct_dataset(sync_transform=sync_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e51383f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux, model = SETR.SETR_Naive_Oct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bcd27a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UVRLab\\.conda\\envs\\assn1\\lib\\site-packages\\torchvision\\transforms\\functional.py:1055: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\n",
      "  \"Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\"\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82c7a292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UVRLab\\.conda\\envs\\assn1\\lib\\site-packages\\torch\\nn\\functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
     ]
    }
   ],
   "source": [
    "output = model(dataset[0][0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5492ee8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1024, 512])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
